---
stepsCompleted: [1, 2, 3, 4]
inputDocuments: []
session_topic: 'D√©veloppement d''une solution de t√©l√©chargement en bulk pour producer.ai (musique, m√©tadonn√©es, stems)'
session_goals: 'Cr√©er un outil pour t√©l√©charger automatiquement 300+ morceaux avec leurs m√©tadonn√©es et pistes s√©par√©es, avec support pour t√©l√©chargement initial massif et synchronisation continue'
selected_approach: 'AI-Recommended Techniques'
techniques_used: ['First Principles Thinking', 'SCAMPER Method', 'Cross-Pollination', 'Decision Tree Mapping']
ideas_generated: 47
session_outcome: 'Architecture compl√®te d√©finie avec roadmap Phase 0-2, stack JavaScript/Node.js, patterns .downloading + state file, target PoC robuste production-ready'
context_file: 'C:\Users\rayan\OneDrive\Documents\Code\BulkDownloadProducerAi\_bmad\bmm\data\project-context-template.md'
---

# Brainstorming Session Results

**Facilitator:** Mon Seigneyr
**Date:** 2026-01-08

## Session Overview

**Topic:** D√©veloppement d'une solution de t√©l√©chargement en bulk pour producer.ai (musique compl√®te, m√©tadonn√©es, pistes s√©par√©es)

**Goals:** Extraire et t√©l√©charger automatiquement toute la biblioth√®que musicale (300+ morceaux), capturer les m√©tadonn√©es associ√©es, t√©l√©charger les pistes s√©par√©es (stems en ZIP), et organiser le tout de mani√®re structur√©e localement. Support pour t√©l√©chargement initial massif et synchronisation continue.

### Context Guidance

Cette session se concentre sur le d√©veloppement d'un outil technique pour r√©soudre un probl√®me d'utilisateur concret : l'absence de fonctionnalit√© de t√©l√©chargement en masse sur producer.ai. L'exploration couvrira :

- **Probl√®me Utilisateur** : Impossibilit√© de t√©l√©charger en masse 300+ cr√©ations musicales
- **Approches Techniques** : Reverse engineering d'API, web scraping, architecture hybride
- **Exp√©rience Utilisateur** : CLI pour PoC, puis Chrome Extension pour UX am√©lior√©e
- **Consid√©rations Techniques** : Formats multiples (WAV/MP3/M4A), stems en ZIP, gestion de volum√©trie importante
- **Valeur Business** : Automatisation d'un processus manuel r√©p√©titif, pr√©servation du contenu cr√©atif

### Session Setup

**Contexte Technique Collect√© :**
- Volume : 300+ morceaux
- Fr√©quence : T√©l√©chargement initial + synchronisation continue
- Niveau technique : Interm√©diaire
- Parcours : CLI (PoC) ‚Üí Chrome Extension (production)
- Formats : Stems (ZIP), Audio (WAV/MP3/M4A)
- ToS : Permissifs ‚úÖ

**Zones d'Exploration :**
1. Stack technologique optimal
2. Strat√©gies d'extraction intelligentes
3. Architecture d'organisation des donn√©es
4. R√©silience et gestion d'erreurs
5. Maintenabilit√© et √©volutivit√©

## Technique Selection

**Approach:** AI-Recommended Techniques
**Analysis Context:** D√©veloppement d'une solution de t√©l√©chargement en bulk pour producer.ai avec focus sur r√©solution de probl√®mes techniques, planification architecturale, et innovation pratique

**Recommended Techniques:**

1. **First Principles Thinking (Creative):** Recommand√©e pour d√©construire producer.ai jusqu'aux fondamentaux, identifier les v√©rit√©s absolues (endpoints API, structure de donn√©es, authentification) et √©liminer les assumptions qui pourraient mener √† des impasses techniques. Dur√©e estim√©e : 15-20 min.

2. **SCAMPER Method (Structured):** Recommand√©e pour explorer syst√©matiquement toutes les options architecturales via 7 lentilles (Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse), cr√©ant un catalogue complet d'options techniques pour chaque composant. Dur√©e estim√©e : 20-25 min.

3. **Cross-Pollination (Creative):** Recommand√©e pour d√©couvrir comment d'autres industries (ETL tools, gestionnaires de m√©dias, outils de backup cloud, download managers) r√©solvent des probl√®mes similaires, permettant d'adapter des patterns √©prouv√©s au lieu de r√©inventer la roue. Dur√©e estim√©e : 15-20 min.

4. **Decision Tree Mapping (Structured):** Recommand√©e pour visualiser tous les chemins de d√©cision et leurs cons√©quences, facilitant des choix architecturaux √©clair√©s et la cr√©ation d'une roadmap claire pour l'impl√©mentation. Dur√©e estim√©e : 15-20 min.

**AI Rationale:** Cette s√©quence √©quilibre analyse profonde (First Principles, Decision Tree), exploration cr√©ative (Cross-Pollination), et planification structur√©e (SCAMPER) pour transformer un probl√®me pratique en solution technique robuste. Total estim√© : 65-85 minutes.

---

## Technique Execution Results

### üîç Technique 1: First Principles Thinking

**Objectif:** D√©construire producer.ai jusqu'aux v√©rit√©s fondamentales en analysant les logs r√©seau (HAR files) pour identifier ce qui est *vraiment* n√©cessaire vs ce qui est assum√©.

#### D√©couvertes Fondamentales (V√©rit√©s Absolues)

**V√âRIT√â #1 : Authentification par Cookies**
- Pas de header `Authorization` complexe
- Les cookies de session font tout le travail automatiquement
- **Implication:** R√©cup√©ration des cookies d'une session navigateur authentifi√©e suffit

**V√âRIT√â #2 : Endpoint de Liste Pagin√©e**
```
/__api/v2/users/{user_id}/generations?offset=0&limit=20
```
- Retourne toute la biblioth√®que avec pagination (20 items par page)
- Format JSON propre, pas de HTML √† scraper
- **Implication:** ~15 requ√™tes API (300√∑20) suffisent pour obtenir tous les generation IDs

**V√âRIT√â #3 : Pattern de T√©l√©chargement Simple**
```
/__api/{generation_id}/download?format=mp3
```
- Un seul endpoint, param√®tre `format` variable: `mp3`, `wav`, `m4a`
- **Implication:** T√©l√©chargement trivial une fois qu'on a les IDs

**V√âRIT√â #4 : Endpoint des Stems (Could Have)**
```
/__api/stems/{generation_id}
```
- Retourne un JSON avec chaque piste s√©par√©e encod√©e en base64
- Structure: `{"stems":{"drums":"[base64]","vocals":"[base64]",...}}`
- **D√©cision:** Reporter aux stems pour phase ult√©rieure (nice-to-have)

**V√âRIT√â #5 : Stockage Google Cloud**
```
https://storage.googleapis.com/corpusant-app-public/riffs/{user_id}/audio/{audio_id}.m4a
```
- Les fichiers ne sont PAS sur les serveurs producer.ai
- **Implication:** T√©l√©chargement direct depuis GCS, pas de rate limiting c√¥t√© producer.ai

#### Conclusions First Principles

**Ce dont on a VRAIMENT besoin:**
1. Authentification: Cookies de session (pas de OAuth complexe)
2. Liste des morceaux: 1 endpoint pagin√© (pas de scraping HTML)
3. T√©l√©chargement audio: 1 endpoint avec param√®tre format
4. M√©tadonn√©es: Probablement dans la r√©ponse `/generations`

**Ce qui √©tait FAUX (Assumptions √©limin√©es):**
- ‚ùå "Les stems sont dans un ZIP" ‚Üí Ils sont en base64 dans JSON
- ‚ùå "Il faut scraper du HTML" ‚Üí API JSON propre existe
- ‚ùå "L'authentification est complexe" ‚Üí Cookies suffisent

---

### üìä Technique 2: SCAMPER Method

**Objectif:** Explorer syst√©matiquement toutes les variations possibles pour chaque composant via 7 lentilles (Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse).

#### D√©cisions SCAMPER Finales

**S - SUBSTITUTE (Remplacer)**
- **Langage:** Full JavaScript (Node.js) pour scalabilit√© vers Chrome Extension
- **Authentification:** Cookies manuels (DevTools copy/paste) pour PoC

**C - COMBINE (Combiner)**
- Stack unifi√© JavaScript (pas de mix Python/JS)
- √âviter la complexit√© de combiner multiples outils

**A - ADAPT (Adapter)**
- **Reprise apr√®s crash:** Skip fichiers existants (taille > 0)
- Pattern inspir√© de download managers professionnels

**M - MODIFY (Modifier)**
- **Validation:** Basique avec 2 retry max
- √âquilibre entre robustesse et simplicit√©

**P - PUT TO OTHER USES (Utiliser autrement)**
- **Scope:** Sp√©cifique √† producer.ai pour PoC
- Extensibilit√© future possible mais pas prioritaire

**E - ELIMINATE (√âliminer)**
- ‚ùå Pas de WAV/M4A (MP3 uniquement pour PoC)
- ‚ùå Pas de stems (report√© en "could have")
- ‚ùå Pas de m√©tadonn√©es JSON s√©par√©es
- ‚ùå Pas de t√©l√©chargements parall√®les (s√©quentiel pour simplicit√©)

**R - REVERSE (Inverser)**
- **Flux streaming:** Fetch page ‚Üí Download ‚Üí Fetch page suivante
- Gratification imm√©diate vs batch complet puis download

#### Organisation des Donn√©es (SCAMPER)

**Nomenclature fichiers:** `{title}_{generation_id}.mp3`
- Titre pour lisibilit√© humaine
- ID pour garantir unicit√©

**Structure dossiers:** Plat (tous dans un seul dossier)
- Simple, cherchable, pas de hi√©rarchie complexe

---

### üîÑ Technique 3: Cross-Pollination

**Objectif:** Emprunter les meilleurs patterns d'autres industries/outils ayant r√©solu des probl√®mes similaires.

#### Patterns Emprunt√©s

**Pattern #1: Download Managers (aria2, IDM)**
```javascript
// Fichier .downloading pendant t√©l√©chargement
const tempFile = `${title}_${id}.mp3.downloading`;
// Renomm√© une fois compl√©t√©
fs.rename(tempFile, `${title}_${id}.mp3`);
```
**Avantage:** Si crash, les `.downloading` sont clairement identifiables comme incomplets

**Pattern #2: ETL Tools (Airflow, Luigi)**
```javascript
// State file pour tracking progression
const state = {
  lastOffset: 40,
  downloaded: 40,
  skipped: 2,
  failed: ["gen-id-xyz"]
};
fs.writeFileSync('download-state.json', JSON.stringify(state));
```
**Avantage:** Reprise exacte apr√®s crash sans regarder les fichiers

**Pattern #3: gallery-dl (Architecture modulaire)**
```
producer-dl/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ auth.js          # Gestion cookies
‚îÇ   ‚îú‚îÄ‚îÄ api.js           # Appels API producer.ai
‚îÇ   ‚îú‚îÄ‚îÄ downloader.js    # T√©l√©chargement fichiers
‚îÇ   ‚îú‚îÄ‚îÄ utils.js         # Helpers (sanitize filename, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ index.js         # Orchestrateur principal
‚îú‚îÄ‚îÄ config.json          # Cookies, output path
‚îî‚îÄ‚îÄ package.json
```

**Pattern #4: rclone (Skip existing intelligent)**
```javascript
function shouldDownload(filepath) {
  if (!fs.existsSync(filepath)) return true;
  const stats = fs.statSync(filepath);
  return stats.size === 0; // Re-download si vide
}
```

**Pattern #5: Strat√©gie Taille + .downloading**
- Combinaison optimale pour garantir int√©grit√© sans complexit√© de checksum
- Checksum jug√© "overkill" pour ce cas d'usage

#### Stack Technique Final (Cross-Pollination)

**HTTP Client:** `node-fetch` (minimaliste, proche de fetch natif)
**Sanitize:** `sanitize-filename` (lib d√©di√©e)
**Progress:** `console.log` simple (pas de barre de progression pour PoC)

---

### üå≥ Technique 4: Decision Tree Mapping

**Objectif:** Cartographier tous les chemins de d√©cision et cr√©er une roadmap d'impl√©mentation optimale.

#### Arbre de D√©cision - Phases d'Impl√©mentation

```
START
  ‚îÇ
  ‚îú‚îÄ Phase 0: SPIKE TECHNIQUE (1-2h) ‚úÖ
  ‚îÇ   ‚îú‚îÄ Validate authentification cookies
  ‚îÇ   ‚îú‚îÄ Validate API pagination structure
  ‚îÇ   ‚îî‚îÄ Validate download MP3 endpoint
  ‚îÇ
  ‚îú‚îÄ Phase 1: PoC MINIMAL (3-4h)
  ‚îÇ   ‚îú‚îÄ Code structure modulaire
  ‚îÇ   ‚îú‚îÄ Pagination loop
  ‚îÇ   ‚îú‚îÄ Download s√©quentiel
  ‚îÇ   ‚îî‚îÄ Basic filename sanitization
  ‚îÇ
  ‚îú‚îÄ Phase 2: PoC ROBUSTE (2-3h) ‚úÖ TARGET
  ‚îÇ   ‚îú‚îÄ Skip existing (size check)
  ‚îÇ   ‚îú‚îÄ .downloading pattern
  ‚îÇ   ‚îú‚îÄ Retry logic (2 max)
  ‚îÇ   ‚îú‚îÄ State file (resume capability)
  ‚îÇ   ‚îî‚îÄ Better logging
  ‚îÇ
  ‚îî‚îÄ Phase 3: CHROME EXTENSION (4-6h, futur)
      ‚îú‚îÄ Manifest + UI
      ‚îú‚îÄ Auto cookies
      ‚îî‚îÄ Progress bar
```

#### D√©cisions Critiques

**D√âCISION #1:** Spike technique d'abord ‚úÖ
- Valider que tout fonctionne AVANT de coder l'architecture compl√®te
- Lever les incertitudes (auth, API, download)

**D√âCISION #2:** Target Phase 2 (PoC Robuste) ‚úÖ
- Production-ready avec retry, skip, resume
- Balance entre MVP et robustesse

**D√âCISION #3:** M√©tadonn√©es dans nom de fichier uniquement ‚úÖ
- Pas de JSON s√©par√©, pas de tags ID3
- KISS principle (Keep It Simple, Stupid)

---

## üéØ Architecture Finale & Roadmap

### Stack Technique Finalis√©

```javascript
{
  "runtime": "Node.js",
  "language": "JavaScript",
  "httpClient": "node-fetch",
  "dependencies": [
    "node-fetch",
    "sanitize-filename"
  ],
  "authentication": "Manual cookies (DevTools)",
  "downloadStrategy": "Sequential streaming",
  "resumeStrategy": "State file + skip existing"
}
```

### Structure de Code Recommand√©e

```
producer-dl/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.js         # Entry point, orchestration
‚îÇ   ‚îú‚îÄ‚îÄ config.js        # Load config.json, validate
‚îÇ   ‚îú‚îÄ‚îÄ auth.js          # Cookie management
‚îÇ   ‚îú‚îÄ‚îÄ api.js           # producer.ai API calls
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetchGenerations(offset, limit)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ getDownloadUrl(generationId, format)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ getUserId()
‚îÇ   ‚îú‚îÄ‚îÄ downloader.js    # Download logic with retry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ downloadTrack(track, outputDir)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shouldSkip(filepath)
‚îÇ   ‚îú‚îÄ‚îÄ state.js         # State file management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loadState()
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ saveState(state)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ updateState(downloaded, skipped, failed)
‚îÇ   ‚îî‚îÄ‚îÄ utils.js         # Helpers
‚îÇ       ‚îú‚îÄ‚îÄ sanitizeFilename(name)
‚îÇ       ‚îî‚îÄ‚îÄ cleanupDownloadingFiles(dir)
‚îú‚îÄ‚îÄ config.json          # User config
‚îÇ   {
‚îÇ     "cookies": "...",
‚îÇ     "userId": "...",
‚îÇ     "outputDir": "./downloads",
‚îÇ     "format": "mp3"
‚îÇ   }
‚îú‚îÄ‚îÄ download-state.json  # Auto-generated
‚îî‚îÄ‚îÄ package.json
```

---

## üìã Roadmap d'Impl√©mentation D√©taill√©e

### Phase 0: Spike Technique (1-2h)

**Objectif:** Valider toutes les incertitudes techniques avant de coder.

**Tasks:**
1. **Test Authentification**
   - Ouvrir producer.ai dans Chrome
   - DevTools ‚Üí Application ‚Üí Cookies
   - Copier tous les cookies du domaine producer.ai
   - Tester avec curl/Postman:
     ```bash
     curl 'https://www.producer.ai/__api/v2/users/YOUR_USER_ID/generations?offset=0&limit=20' \
       -H 'Cookie: YOUR_COOKIES_HERE'
     ```

2. **Test API Pagination**
   - Analyser la structure JSON de la r√©ponse
   - V√©rifier pr√©sence de: `title`, `id`, `created_at`, etc.
   - Tester offset=20, 40, 60 pour valider pagination
   - Identifier le `user_id` √† utiliser

3. **Test Download Endpoint**
   - Prendre un `generation_id` du r√©sultat
   - Appeler: `/__api/{generation_id}/download?format=mp3`
   - Sauvegarder et v√©rifier que le fichier joue
   - Mesurer taille typique d'un fichier MP3

**Success Criteria:**
- ‚úÖ Les cookies fonctionnent pour l'authentification
- ‚úÖ L'API retourne bien la liste compl√®te des morceaux
- ‚úÖ Le t√©l√©chargement MP3 fonctionne
- ‚úÖ La structure JSON des m√©tadonn√©es est comprise

---

### Phase 1: PoC Minimal (3-4h)

**Objectif:** Script fonctionnel end-to-end sans robustesse.

**Implementation Order:**

1. **Setup projet**
   ```bash
   mkdir producer-dl && cd producer-dl
   npm init -y
   npm install node-fetch sanitize-filename
   ```

2. **Cr√©er `config.json`**
   ```json
   {
     "cookies": "YOUR_COOKIES_FROM_DEVTOOLS",
     "userId": "YOUR_USER_ID",
     "outputDir": "./downloads",
     "format": "mp3"
   }
   ```

3. **`src/api.js` - Basic API calls**
   ```javascript
   import fetch from 'node-fetch';

   export async function fetchGenerations(cookies, userId, offset = 0, limit = 20) {
     const url = `https://www.producer.ai/__api/v2/users/${userId}/generations?offset=${offset}&limit=${limit}`;
     const response = await fetch(url, {
       headers: { 'Cookie': cookies }
     });
     return await response.json();
   }

   export function getDownloadUrl(generationId, format = 'mp3') {
     return `https://www.producer.ai/__api/${generationId}/download?format=${format}`;
   }
   ```

4. **`src/downloader.js` - Basic download**
   ```javascript
   import fetch from 'node-fetch';
   import fs from 'fs';
   import path from 'path';
   import sanitize from 'sanitize-filename';

   export async function downloadTrack(track, cookies, outputDir, format) {
     const filename = sanitize(`${track.title}_${track.id}.${format}`);
     const filepath = path.join(outputDir, filename);
     const url = getDownloadUrl(track.id, format);

     const response = await fetch(url, {
       headers: { 'Cookie': cookies }
     });

     const buffer = await response.buffer();
     fs.writeFileSync(filepath, buffer);

     console.log(`‚úÖ Downloaded: ${filename}`);
     return { status: 'success', file: filename };
   }
   ```

5. **`src/index.js` - Main orchestration**
   ```javascript
   import fs from 'fs';
   import { fetchGenerations } from './api.js';
   import { downloadTrack } from './downloader.js';

   async function main() {
     const config = JSON.parse(fs.readFileSync('./config.json'));
     fs.mkdirSync(config.outputDir, { recursive: true });

     let offset = 0;
     const limit = 20;
     let hasMore = true;

     while (hasMore) {
       console.log(`üì• Fetching page offset=${offset}...`);
       const data = await fetchGenerations(config.cookies, config.userId, offset, limit);

       const tracks = data.generations || [];
       if (tracks.length === 0) {
         hasMore = false;
         break;
       }

       for (const track of tracks) {
         await downloadTrack(track, config.cookies, config.outputDir, config.format);
       }

       offset += limit;
     }

     console.log('üéâ All downloads complete!');
   }

   main().catch(console.error);
   ```

**Success Criteria Phase 1:**
- ‚úÖ Script t√©l√©charge tous les morceaux du d√©but √† la fin (si pas de crash)
- ‚úÖ Fichiers sauvegard√©s avec nom: `{title}_{id}.mp3`
- ‚úÖ Code modulaire et lisible

---

### Phase 2: PoC Robuste (2-3h) - TARGET

**Objectif:** Ajouter retry, skip existing, state file, .downloading pattern.

**Features √† impl√©menter:**

1. **Skip Existing + .downloading Pattern**
   ```javascript
   // downloader.js
   export async function downloadTrack(track, cookies, outputDir, format) {
     const filename = sanitize(`${track.title}_${track.id}.${format}`);
     const finalPath = path.join(outputDir, filename);
     const tempPath = `${finalPath}.downloading`;

     // Skip si d√©j√† t√©l√©charg√©
     if (fs.existsSync(finalPath)) {
       const stats = fs.statSync(finalPath);
       if (stats.size > 0) {
         console.log(`‚è≠Ô∏è  Skipping: ${filename} (exists, ${stats.size} bytes)`);
         return { status: 'skipped', file: filename };
       }
     }

     // Nettoyer ancien .downloading si pr√©sent
     if (fs.existsSync(tempPath)) {
       fs.unlinkSync(tempPath);
     }

     // Download to .downloading
     try {
       const url = getDownloadUrl(track.id, format);
       const response = await fetch(url, {
         headers: { 'Cookie': cookies }
       });
       const buffer = await response.buffer();
       fs.writeFileSync(tempPath, buffer);

       // Rename to final
       fs.renameSync(tempPath, finalPath);
       console.log(`‚úÖ Downloaded: ${filename}`);
       return { status: 'success', file: filename };
     } catch (error) {
       // Cleanup failed .downloading
       if (fs.existsSync(tempPath)) {
         fs.unlinkSync(tempPath);
       }
       throw error;
     }
   }
   ```

2. **Retry Logic (2 max)**
   ```javascript
   async function downloadWithRetry(track, cookies, outputDir, format, maxRetries = 2) {
     for (let attempt = 1; attempt <= maxRetries; attempt++) {
       try {
         return await downloadTrack(track, cookies, outputDir, format);
       } catch (error) {
         if (attempt === maxRetries) {
           console.error(`‚ùå Failed after ${maxRetries} attempts: ${track.title}`);
           return { status: 'failed', file: track.title, error: error.message };
         }
         console.warn(`‚ö†Ô∏è  Retry ${attempt}/${maxRetries}: ${track.title}`);
         await sleep(1000 * attempt); // Exponential backoff
       }
     }
   }
   ```

3. **State File Management**
   ```javascript
   // state.js
   export function loadState() {
     if (fs.existsSync('./download-state.json')) {
       return JSON.parse(fs.readFileSync('./download-state.json'));
     }
     return { lastOffset: 0, downloaded: 0, skipped: 0, failed: [] };
   }

   export function saveState(state) {
     fs.writeFileSync('./download-state.json', JSON.stringify(state, null, 2));
   }
   ```

4. **Cleanup Orphaned .downloading**
   ```javascript
   // utils.js
   export function cleanupDownloadingFiles(dir) {
     const files = fs.readdirSync(dir);
     const downloading = files.filter(f => f.endsWith('.downloading'));
     downloading.forEach(f => {
       fs.unlinkSync(path.join(dir, f));
       console.log(`üßπ Cleaned up: ${f}`);
     });
   }
   ```

5. **Enhanced index.js with Resume**
   ```javascript
   async function main() {
     const config = JSON.parse(fs.readFileSync('./config.json'));
     fs.mkdirSync(config.outputDir, { recursive: true });

     // Cleanup orphaned files
     cleanupDownloadingFiles(config.outputDir);

     // Load state
     const state = loadState();
     let offset = state.lastOffset;

     const stats = { downloaded: 0, skipped: 0, failed: 0 };

     while (true) {
       console.log(`\nüì• Fetching page offset=${offset}...`);
       const data = await fetchGenerations(config.cookies, config.userId, offset, 20);

       if (!data.generations || data.generations.length === 0) break;

       for (const track of data.generations) {
         const result = await downloadWithRetry(track, config.cookies, config.outputDir, config.format);
         stats[result.status]++;
         if (result.status === 'failed') {
           state.failed.push(track.id);
         }
       }

       offset += 20;
       state.lastOffset = offset;
       saveState(state);
     }

     console.log('\nüéâ Download complete!');
     console.log(`Downloaded: ${stats.downloaded}, Skipped: ${stats.skipped}, Failed: ${stats.failed}`);
   }
   ```

**Success Criteria Phase 2:**
- ‚úÖ Si crash ‚Üí reprend o√π √ßa s'est arr√™t√© via state file
- ‚úÖ Si re-run ‚Üí skip automatiquement les d√©j√† t√©l√©charg√©s
- ‚úÖ Si erreur r√©seau ‚Üí retry 2x avant abandon
- ‚úÖ Fichiers .downloading nettoy√©s au d√©marrage
- ‚úÖ Logging clair avec statistiques finales

---

## ‚úÖ Checklist d'Ex√©cution

### Phase 0: Spike
- [ ] Extraire cookies depuis DevTools
- [ ] Tester API `/generations` avec curl
- [ ] Analyser structure JSON
- [ ] Tester download endpoint
- [ ] Documenter findings

### Phase 1: PoC Minimal
- [ ] Initialiser projet Node.js
- [ ] Installer dependencies (node-fetch, sanitize-filename)
- [ ] Cr√©er config.json avec cookies
- [ ] Coder src/api.js
- [ ] Coder src/downloader.js
- [ ] Coder src/index.js
- [ ] Test run avec 1-2 pages
- [ ] Valider fichiers t√©l√©charg√©s jouent correctement

### Phase 2: PoC Robuste
- [ ] Impl√©menter pattern .downloading
- [ ] Impl√©menter skip existing (size check)
- [ ] Impl√©menter retry logic (2 max)
- [ ] Impl√©menter state file (load/save)
- [ ] Impl√©menter cleanup orphaned files
- [ ] Enhanced logging avec stats
- [ ] Test: crash & resume
- [ ] Test: re-run avec fichiers existants
- [ ] Test: erreur r√©seau (d√©brancher wifi)
- [ ] Documentation README

---

## üöÄ Next Steps (Post-Phase 2)

**Could Have (Futur):**
- [ ] Support multi-format (WAV, M4A)
- [ ] T√©l√©chargement stems (base64 decode)
- [ ] M√©tadonn√©es JSON s√©par√©es
- [ ] T√©l√©chargements parall√®les
- [ ] Barre de progression CLI
- [ ] Chrome Extension UI

**Nice to Have:**
- [ ] Tests unitaires
- [ ] CI/CD
- [ ] Docker container
- [ ] NPM package publication

---

## üí° Key Insights & Lessons Learned

### Breakthrough Moments

1. **First Principles r√©v√©lation:** L'analyse des HAR files a r√©v√©l√© que producer.ai utilise des API JSON propres, √©liminant le besoin de scraping HTML complexe.

2. **Pattern .downloading + skip existing:** La combinaison de ces deux patterns garantit l'int√©grit√© des fichiers sans la complexit√© des checksums.

3. **Streaming vs Batch:** Le choix du flux streaming (fetch page ‚Üí download ‚Üí next page) permet une gratification imm√©diate et une meilleure gestion m√©moire.

4. **KISS Principle appliqu√©:** Choix pragmatiques (MP3 only, nom de fichier pour metadata, s√©quentiel) permettent un PoC rapide et fonctionnel.

### D√©cisions Architecturales Critiques

- **Full JavaScript:** Vision unifi√©e CLI ‚Üí Chrome Extension
- **Modulaire d√®s Phase 1:** Code maintenable et testable
- **State file:** Reprise robuste apr√®s crash
- **Manual cookies pour PoC:** √âvite complexit√© Puppeteer

### Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Cookies expirent | Bloque tout | Documenter comment refresh cookies |
| API change | Casse tool | Phase 0 validation + tests r√©guliers |
| Rate limiting | Ralentit download | S√©quentiel + monitoring |
| Nom fichiers invalides | Crash save | sanitize-filename lib |

---

## üìö Resources & References

**Patterns inspir√©s de:**
- aria2 (download manager) - Pattern .part/.downloading
- rclone (sync tool) - Skip existing strategies
- gallery-dl (media downloader) - Architecture modulaire
- ETL tools - State file pour tracking

**Librairies Node.js:**
- node-fetch: HTTP client minimaliste
- sanitize-filename: Nettoyage noms de fichiers

**Documentation producer.ai:**
- Endpoints d√©couverts via reverse engineering (HAR analysis)
- ToS: Permissifs pour usage personnel

---

_Session facilit√©e par Mary, Business Analyst - 2026-01-08_
_Dur√©e totale: ~85 minutes_
_Techniques utilis√©es: First Principles Thinking, SCAMPER Method, Cross-Pollination, Decision Tree Mapping_
